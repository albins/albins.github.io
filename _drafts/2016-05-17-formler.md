---
layout: post
title: Formler till Sannolikhet och Statistik DV, HT 2016
---

Det här är alltså tänkt att ~~vara~~ bli formelbladet vi borde ha fått till Sannolikhet och statistik DV. Jag vet inte ens vad jag heter längre, men jag kan räkna på det. Om du vill hjälpa till – skicka en ~~pull request~~ dragförfrågan mot [den här filen i git-repon](https://github.com/albins/albins.github.io/blob/master/_posts/2016-05-17-formler.md)!

## Mängdaritmetik på slumpvariabler

### Definitioner

- A, B, etc är en _händelse_ ("jag drar ett spader ess ur leken").
- Alla händelser är delmängder av ett utfallsrum, S, som innefattar _alla möjliga händelser_ ("jag drar ett spader ess eller ett...")
- P(A) o.s.v. är sannolikheten för att händelsen _inträffar_ (1 av 52 kort är ett spader ess)
- P(S) = 1, P(A) ≥ 0 för alla händelser.
- \\( P(\emptyset) = 0 \\) (tomma mängden = den omöjliga händelsen)

### Komplement (\\( A^* \\))

Komplementet för händelsen A innebär sannolikheten för att A _inte_ inträffar.

\\[ P(A^*) = 1 - P(A) \\]

**Tips**: Eftersom summan av sannolikheter alltid är 1 enligt [Kolmogorovs axiom](https://en.wikipedia.org/wiki/Probability_axioms) gäller att allt _utom_ A (d.v.s. komplementet) måste vara 1 - A.

### Union (\\( \cup \\))
Unionen av två händelser innebär att _någon av dem inträffar_ (läs som "A eller B").

_Oavsett_ om A och B är oförenliga gäller:
\\[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \\]

**Tips**: Tänk att sannolikheten för unionen av (_någon av_) A och B är sannolikheten för A, plus sannolikheten för B, minus ytan där de överlappar.

Om händelserna A och B är _oförenliga_ gäller alltså:
\\[ P(A \cup B) = P(A) + P(B) \\]

**Tips**: Eftersom A och B är oförenliga är deras överlappning den tomma mängden (de är aldrig sanna samtidigt). Därför försvinner _alltid_ den sista termen i summan.

### Snitt (\\( \cap \\))
Snittet av två händelser innebär att _båda två inträffar_ (läs som "A och B").

Om A och B är _oberoende_:
\\[ P(A \cap B) = P(A) P(B) \\]

Om A och B är oförenliga är snittet den tomma mängden, \\( \varnothing \\).

### Betingad sannolikhet (\\( P(A\|B) \\))
Läs som "A förutsatt B".

\\[ P(A\|B) = \frac{P(A \cap B)}{P(B)} \\]

**Tips**: Läs ut den som "sannolikheten för A givet B är sannolikheten för både A och B, givet att (normerat på) vi vet att B redan har hänt".

#### Bayes formel

\\[ P(B \| A) = \frac{P(B)}{P(A)} P(A \|B) \\]

### De Morgans regler för mängdoperationer
De Morgans regler säger att:
\\[ (A \cup B)^* \equiv A^* \cap B^* \\\
  (A \cap B)^* \equiv A^* \cup B^* \\]

**Tips**: "break the line // change the sign". Tänk på multiplikation med negativa tal som motsvarigheten till komplement!

## Stokastiska variabler

### Definitioner
- En stokastisk variabel \\( \mathbb{X}(u) \\) är ett _villkor_ på händelser som kan räknas; något händer u gånger eller har mängden/storleken u. Se det som ett filter på mängden av händelser!
- Kan vara diskreta (\\( u \in \mathbb{Z} \\)) eller kontinuerliga (\\( u \in \mathbb{R} \\))

### Från händelser till stokastiska variabler

Säg att vi kan teckna kontrakt vid tre händelser: A, B och C.

Låt \\( \mathbb{X}(u) = \\) antal tecknade kontrakt. u är förstås diskret (vi kan inte teckna ett halvt kontrakt).

Då gäller att \\( \mathbb{P}(X = 0) = P(A^* \cap B^* \cap C^*) \\), eftersom vi tecknar exakt noll kontrakt genom att misslyckas vid alla tre tillfällen: A, B och C.

Samma metod kan användas för intervallvillkor: \\( \mathbb{P}(\mathbb{X} \ge 2) \\) innebär i sådana fall att minst två (alltså två eller tre eller...) kontrakt tecknas.

## Fördelningsfunktioner och täthetsfunktioner

### Definitioner
- \\( F_{\mathbb{X}}(u) \\) är fördelningsfunktionen för den stokastiska variabeln \\(\mathbb{X}(u)\\)
- Om det finns en funktion \\( f_{\mathbb{X}} = F'\_{\mathbb{X}} \\) så är \\(\mathbb{X}\\) kontinuerlig och har _täthetsfunktionen_ \\( f_{\mathbb{X}} \\)
- \\( f_{\mathbb{X}}(u) \overset{\text{def.}}{\equiv} \mathbb{P}(X = u) \\)
- Av ovanstående följer att \\( \mathbb{P}(a < \mathbb{X} < b) = \int_a^b f_{\mathbb{X}}(u)\ \mathrm{d} u \\) (arean under grafen = integralen = summan av sannolikheter för alla möjliga tillstånd i intervallet)
- Av allt ovan och Kolmogorovs axiom följer att \\( \mathbb{P}(-\infty < \mathbb{X} < +\infty) = 1 \\)

### Vanliga fördelningsfunktioner

| \\( \mathbb{X} \sim \\) | \\(\mathbb{E}(\mathbb{X}) \\) | \\(\mathbb{V}(\mathbb{X}) \\) | \\(\mathbb{P}(\mathbb{X} = x) \\)
| Bin(n, p)               | \\( np \\)                    | \\( np (1-p) \\)              | \\({n \choose x} p^x (1-p)^{n-x} \\)
| Po(m)                   | m                             | m                             | \\( \frac{m^x}{x!} e^{-m} \\)

#### Tolkningar

## Summor, produkter och andra funktioner av stokastiska variabler

För normalfördelade variabler gäller:
\\[ (X + Y) \sim N(\mathbb{E}(X) + \mathbb{E}(Y), \mathbb{V}(X) + \mathbb{V}(Y)) \\]

För binomialfördelade variabler gäller:

För Poissonfördelade variabler gäller:

**Tips:** Singla tre slantar, singla tre slantar till, det är samma sak som att singla sex slandar redan från början.

## Indikatorvariabler (\\(1_{\\{ \mathbb{X} = 1 \\}}\\))

En indikatorvariabel \\(1\_{\\{ \mathbb{X} = 1 \\}}\\) är 1 när påståendet inom spetsparenteserna är sant, 0 annars. Det betyder att väntevärdet följer av sannolikheten för det villkoret:

\\[ \mathbb{E}(1_{\\{ \mathbb{X} = 1 \\}}) = 1 \cdot \mathbb{P}(\mathbb{X} = 1) + 0 \cdot \mathbb{P}(\mathbb{X} \neq 1) \\]

## Väntevärde (\\( \mathbb{E} \\)) och varians (\\( \mathbb{V} \\))

### Definitioner
För diskreta variabler:
\\[ \mathbb{E}(X) = \sum_i^{\infty} x_i p(x_i) \\]

där \\(p(x_i) \\) är sannolikhetsfunktionen för X.

För kontinuerliga variabler:
\\[ \mathbb{E}(X) = \int_{-\infty}^{+\infty} x f(x) \mathrm{d}x \\]

där \\(f(x) \\) är täthetsfunktionen för X.

För en funktion, \\( g(X) \\) är väntevärdet:
\\[ \mathbb{E}(g(X)) = \sum_i^{\infty} g(x_i) p(x_i) \\]

för diskreta X, eller:

\\[ \mathbb{E}(X) = \int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d}x \\]

för kontinuerliga X.

Varians från väntevärde (och kvadrat):
\\[ \mathbb{V}(X) = \mathbb{E}(X^2) - (\mathbb{E}(X))^2 \\]

### Väntevärde och varians för summor och produkter

Låt \\(Z = X + Y \\). Då är \\(\mathbb{E}(Z) = \mathbb{E}(X) + \mathbb{E}(Y)\\). Dessutom gäller:

\\[ \mathbb{E}(aX) = a\mathbb{E}(X) \\]
\\[ \mathbb{E}(X + a) = \mathbb{E}(X) + a \\]

Och 
\\[ \mathbb{V}(aX + b) = a^2\mathbb{V}(X) \\]

## Kvantiler och konfidensintervall

Om \\(\sigma\\) är **okänd** ges \\((1-\alpha) \cdot 100\\)%-konfidensintervallet för väntevärdet av t-fördelningen (av n värden):
\\[I_m = \overline{x} \pm t_{\alpha/2} (n - 1) \cdot \frac{s}{\sqrt{n}} \\]

Om \\(\sigma\\) är **känd** ges \\((1-\alpha) \cdot 100\\)%-konfidensintervallet för väntevärdet av normalfördelningen (av n värden):
\\[I_m = \overline{x} \pm \lambda_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}} \\]

Man slår upp båda värdena i en tabell enligt rad = argument till t, kolumn = \\(\alpha\\).

## Saker man kan göra med stickprov

### Medelvärde av stickprov (aritmetiskt medelvärde)
\\[\bar{x} = \frac{1}{n} \Sigma_{i=1}^n x_i = \frac{1}{n} (x_1 + \ldots + x_n) \\]

### Stickprovsvarians

\\[s^2 = \frac{1}{n-1} \Sigma_{i=1}^n(x_i - \bar{x})^2 \\]

Där \\( \bar{x} \\) är det aritmetiska medelvärdet av stickprovet.

### Korrelationskoefficient


### Skatta väntevärde och varians från stickprov

## Slump och slumptal (från datorer)

## Processer

### Definitioner

### Sannolikheter från Poisson-processer

:fish:

En poisson-process är i princip en räknare över hur många gånger något har hänt (i en simulering) ("hur många asteroider (n) har vid tiden t träffat jorden?"). För att få ut sannolikheten för ett visst n (antal asteroider) vid en viss tid (t = 1239 sekunder från simulationens start), uppställd som \\( N(t) = n \\), använd följande formel (av Poisson-fördelningen):

\\[ \mathbb{P}(N(t) = n) = e^{-\lambda t} \frac{(\lambda t)^n}{n!} \\]

**Tips**: Om du jämför med formeln för Po-fördelning ser du att väntevärdet är \\( \lambda t \\). Det beror på att λ är en _intensitet_ (732 träffade asteroider per sekund) och t är en tid. Antalet asteroider vi kan vänta oss efter t = 5 sekunder är m.a.o \\( 5 \cdot 732 \\) stycken!

### Spatiala Poissonprocesser
En spatial Poissonprocess är _exakt samma_ som en över tid (eller något annat). Tolka bara tiden som area (d.v.s. istället för "vad är sannolikheten att 3 meteoriter har träffat jorden efter 300 sekunder", "vad är sannolikheten att 3 meteoriter har träffat en yta av 300 kvadratmeter givet λ = 3 nedslag/m²?").

### Summor av Poisson-processer

## Markovkedjor

### Övergångsdiagram till övergångsmatris

## Hashar
- Antal förväntade kollissioner för n objekt i m platser:
- Antal förväntade lediga platser för n objekt av m möjliga platser:

## Bra-att-ha-samband och regler

### Logaritmlagar
\\[ \ln(xy)=\ln(x) + \ln(y) \\]
\\[ \ln(\tfrac{x}{y})=\ln(x)-\ln(y) \\]
\\[ \ln(x^d)=d\ln(x) \\]

### Kombinatorik

n saker att välja från, välj k stycken:
\\[ {n \choose k} = \frac{n!}{k!(n - k)!} \\]

## Föreläsningsanteckningar

[På Dropbox](https://www.dropbox.com/sh/7oilvjg9pmvs7qf/AADToRLlvUZm-RBfYFQahgc3a?dl=0).
